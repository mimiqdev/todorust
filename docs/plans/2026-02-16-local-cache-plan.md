# Local Cache Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** å®ç°æœ¬åœ°ç¼“å­˜åŠŸèƒ½ï¼Œåˆ©ç”¨ Todoist Sync API çš„ sync_token åšå¢é‡åŒæ­¥ï¼Œå‡å°‘ API è°ƒç”¨

**Architecture:** åœ¨ src/sync/ ä¸‹æ–°å¢ cache.rs æ¨¡å—ï¼Œç®¡ç† cache.json çš„è¯»å†™ï¼›åœ¨ TodoistSyncClient ä¸­é›†æˆç¼“å­˜é€»è¾‘ï¼›CLI æ–°å¢ sync/cache å‘½ä»¤

**Tech Stack:** Rust, serde_json, std::fs

---

## Task 1: åˆ›å»º Cache æ•°æ®ç»“æ„å’ŒåŸºç¡€æ¨¡å—

**Files:**
- Create: `src/sync/cache.rs`
- Modify: `src/sync/mod.rs`
- Test: `tests/unit/cache_test.rs`

**Step 1: åˆ›å»º cache.rs åŸºç¡€ç»“æ„**

```rust
// src/sync/cache.rs
use serde::{Deserialize, Serialize};
use std::path::PathBuf;

#[derive(Serialize, Deserialize, Default)]
pub struct Cache {
    pub sync_token: String,
    pub cached_at: i64,
    pub data: CacheData,
}

#[derive(Serialize, Deserialize, Default)]
pub struct CacheData {
    pub projects: Vec<super::models::SyncProject>,
    pub items: Vec<super::models::SyncTask>,
    pub sections: Vec<super::models::SyncSection>,
    pub labels: Vec<super::models::SyncLabel>,
    pub filters: Vec<super::models::SyncFilter>,
}

pub struct CacheManager {
    cache_path: PathBuf,
}

impl CacheManager {
    pub fn new() -> Self {
        let config_dir = dirs::config_dir()
            .unwrap_or_else(|| PathBuf::from("."))
            .join("todorust");
        Self {
            cache_path: config_dir.join("cache.json"),
        }
    }

    pub fn load(&self) -> Result<Option<Cache>, crate::error::TodoError> {
        if !self.cache_path.exists() {
            return Ok(None);
        }
        let content = std::fs::read_to_string(&self.cache_path)?;
        let cache: Cache = serde_json::from_str(&content).map_err(|e| {
            crate::error::TodoError::InvalidInput(format!("Failed to parse cache: {}", e))
        })?;
        Ok(Some(cache))
    }

    pub fn save(&self, cache: &Cache) -> Result<(), crate::error::TodoError> {
        if let Some(parent) = self.cache_path.parent() {
            std::fs::create_dir_all(parent)?;
        }
        let content = serde_json::to_string_pretty(cache).map_err(|e| {
            crate::error::TodoError::InvalidInput(format!("Failed to serialize cache: {}", e))
        })?;
        std::fs::write(&self.cache_path, content)?;
        Ok(())
    }

    pub fn is_expired(&self, cache: &Cache, threshold_secs: u64) -> bool {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map(|d| d.as_secs() as i64)
            .unwrap_or(0);
        (now - cache.cached_at) > threshold_secs as i64
    }
}
```

**Step 2: æ›´æ–° src/sync/mod.rs å¯¼å‡º cache æ¨¡å—**

```rust
pub mod cache;
pub mod client;
pub mod commands;
pub mod models;
```

**Step 3: æ·»åŠ  dirs ä¾èµ–åˆ° Cargo.toml**

```toml
[dependencies]
dirs = "5"
```

**Step 4: è¿è¡Œ cargo build éªŒè¯ç¼–è¯‘**

Run: `cd .worktrees/local-cache && cargo build`
Expected: COMPILATION ERROR (dirs not found) - add it

**Step 5: æ·»åŠ  dirs åé‡æ–°ç¼–è¯‘**

Run: `cd .worktrees/local-cache && cargo build`
Expected: SUCCESS

**Step 6: æäº¤**

```bash
cd .worktrees/local-cache
git add src/sync/cache.rs src/sync/mod.rs Cargo.toml
git commit -m "feat: add cache module with CacheManager"
```

---

## Task 2: é›†æˆç¼“å­˜åˆ° TodoistSyncClient

**Files:**
- Modify: `src/sync/client.rs`
- Test: `tests/unit/client_cache_test.rs`

**Step 1: ä¿®æ”¹ TodoistSyncClient ç»“æ„ä½“ï¼Œæ·»åŠ ç¼“å­˜æ”¯æŒ**

åœ¨ `src/sync/client.rs` ä¸­æ·»åŠ :

```rust
use super::cache::{Cache, CacheData, CacheManager};

pub struct TodoistSyncClient {
    token: String,
    sync_url: String,
    sync_token: RefCell<Option<String>>,
    http: HttpClient,
    cache_manager: CacheManager,
    cache: RefCell<Option<Cache>>,
}
```

**Step 2: ä¿®æ”¹ new() åˆå§‹åŒ– cache_manager**

```rust
impl TodoistSyncClient {
    pub fn new(token: String) -> Self {
        // ... existing code ...
        Self {
            // ... existing fields ...
            cache_manager: CacheManager::new(),
            cache: RefCell::new(None),
        }
    }
}
```

**Step 3: æ·»åŠ ç¼“å­˜åŒæ­¥æ–¹æ³•**

```rust
impl TodoistSyncClient {
    /// å°è¯•ä»ç¼“å­˜åŠ è½½æ•°æ®
    pub fn load_cache(&self) -> Result<Option<Cache>, TodoError> {
        self.cache_manager.load()
    }

    /// ä¿å­˜ç¼“å­˜
    pub fn save_cache(&self, sync_token: &str, data: CacheData) -> Result<(), TodoError> {
        let cache = Cache {
            sync_token: sync_token.to_string(),
            cached_at: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .map(|d| d.as_secs() as i64)
                .unwrap_or(0),
            data,
        };
        self.cache_manager.save(&cache)
    }

    /// æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ (é»˜è®¤ 5 åˆ†é’Ÿ)
    pub fn is_cache_expired(&self) -> bool {
        if let Some(ref cache) = *self.cache.borrow() {
            self.cache_manager.is_expired(cache, 300)
        } else {
            true
        }
    }

    /// è·å–ç¼“å­˜æ•°æ®
    pub fn get_cached_data(&self) -> Option<CacheData> {
        self.cache.borrow().as_ref().map(|c| c.data.clone())
    }
}
```

**Step 4: ä¿®æ”¹ sync() æ–¹æ³•ï¼Œåœ¨æˆåŠŸåä¿å­˜ç¼“å­˜**

åœ¨ `sync` æ–¹æ³•æœ«å°¾æ·»åŠ :

```rust
// ä¿å­˜åˆ°ç¼“å­˜
let data = CacheData {
    projects: response.projects.clone(),
    items: response.items.clone(),
    sections: response.sections.clone(),
    labels: response.labels.clone(),
    filters: response.filters.clone(),
};
self.save_cache(&response.sync_token, data)?;
```

**Step 5: è¿è¡Œ cargo build**

Run: `cd .worktrees/local-cache && cargo build`
Expected: SUCCESS

**Step 6: æäº¤**

```bash
cd .worktrees/local-cache
git add src/sync/client.rs
git commit -m "feat: integrate cache into TodoistSyncClient"
```

---

## Task 3: å®ç°æ··åˆåŒæ­¥é€»è¾‘

**Files:**
- Modify: `src/sync/client.rs`
- Modify: `src/cli/handlers.rs`

**Step 1: åœ¨ TodoistSyncClient æ·»åŠ æ··åˆåŒæ­¥æ–¹æ³•**

```rust
impl TodoistSyncClient {
    /// æ··åˆåŒæ­¥ï¼šä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼Œå¿…è¦æ—¶å¢é‡/å…¨é‡åŒæ­¥
    pub async fn sync_with_cache(&self, resource_types: &[&str]) -> Result<SyncReadResponse, TodoError> {
        // å°è¯•åŠ è½½ç¼“å­˜
        if self.cache.borrow().is_none() {
            if let Ok(Some(cache)) = self.cache_manager.load() {
                *self.cache.borrow_mut() = Some(cache);
            }
        }

        // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        let needs_full_sync = self.is_cache_expired() || self.sync_token.borrow().is_none();

        if needs_full_sync {
            // å…¨é‡åŒæ­¥
            tracing::info!("Performing full sync");
            let response = self.sync(resource_types).await?;
            *self.sync_token.borrow_mut() = Some(response.sync_token.clone());
            return Ok(response);
        }

        // å¢é‡åŒæ­¥
        tracing::info!("Performing incremental sync");
        let response = self.sync(resource_types).await?;
        *self.sync_token.borrow_mut() = Some(response.sync_token.clone());
        Ok(response)
    }
}
```

**Step 2: ä¿®æ”¹ handlers.rs ä¸­çš„ get_tasks ç­‰æ–¹æ³•ä½¿ç”¨ç¼“å­˜**

```rust
// åœ¨ get_tasks å‡½æ•°ä¸­
let response = client.sync_with_cache(&["items"]).await?;
let tasks = response.items;
```

**Step 3: è¿è¡Œ cargo build**

Run: `cd .worktrees/local-cache && cargo build`
Expected: SUCCESS

**Step 4: æäº¤**

```bash
cd .worktrees/local-cache
git add src/sync/client.rs src/cli/handlers.rs
git commit -m "feat: implement hybrid sync with cache"
```

---

## Task 4: æ·»åŠ  CLI sync å‘½ä»¤

**Files:**
- Modify: `src/cli/mod.rs`
- Modify: `src/main.rs`

**Step 1: åœ¨ cli/mod.rs æ·»åŠ  SyncCommands æšä¸¾**

```rust
#[derive(Parser)]
pub enum SyncCommands {
    /// åŒæ­¥æ•°æ® (é»˜è®¤å¢é‡ï¼Œ--force å…¨é‡)
    Sync {
        #[arg(long)]
        force: bool,
    },
}
```

**Step 2: åœ¨ Commands æšä¸¾æ·»åŠ  sync å˜ä½“**

```rust
pub enum Commands {
    // ... existing ...
    Sync(SyncCommands),
    Cache(CacheCommands),
}
```

**Step 3: æ·»åŠ  CacheCommands æšä¸¾**

```rust
#[derive(Parser)]
pub enum CacheCommands {
    /// æ˜¾ç¤ºç¼“å­˜çŠ¶æ€
    Status,
    /// æ¸…é™¤ç¼“å­˜
    Clear,
}
```

**Step 4: åœ¨ main.rs å®ç° sync/cache å‘½ä»¤å¤„ç†**

```rust
Commands::Sync(SyncCommands::Sync { force }) => {
    let response = if force {
        client.sync(&["projects", "items", "sections", "labels", "filters"]).await?
    } else {
        client.sync_with_cache(&["projects", "items", "sections", "labels", "filters"]).await?
    };
    println!("Synced: {} projects, {} tasks", response.projects.len(), response.items.len());
}
Commands::Cache(CacheCommands::Status) => {
    if let Ok(Some(cache)) = client.load_cache() {
        println!("Cached at: {}", cache.cached_at);
        println!("Projects: {}", cache.data.projects.len());
        println!("Tasks: {}", cache.data.items.len());
    } else {
        println!("No cache found");
    }
}
Commands::Cache(CacheCommands::Clear) => {
    client.clear_cache()?;
    println!("Cache cleared");
}
```

**Step 5: åœ¨ TodoistSyncClient æ·»åŠ  clear_cache æ–¹æ³•**

```rust
pub fn clear_cache(&self) -> Result<(), TodoError> {
    if self.cache_manager.cache_path.exists() {
        std::fs::remove_file(&self.cache_manager.cache_path)?;
    }
    *self.cache.borrow_mut() = None;
    Ok(())
}
```

**Step 6: è¿è¡Œ cargo build**

Run: `cd .worktrees/local-cache && cargo build`
Expected: SUCCESS

**Step 7: æäº¤**

```bash
cd .worktrees/local-cache
git add src/cli/mod.rs src/main.rs src/sync/client.rs
git commit -m "feat: add sync and cache CLI commands"
```

---

## Task 5: æµ‹è¯•è¦†ç›–

**Files:**
- Create: `tests/unit/cache_test.rs`
- Modify: `tests/integration_test.rs`

**Step 1: å•å…ƒæµ‹è¯•**

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use std::fs;
    use tempfile::TempDir;

    #[test]
    fn test_cache_save_load() {
        let temp_dir = TempDir::new().unwrap();
        let cache_path = temp_dir.path().join("cache.json");
        
        let cache = Cache {
            sync_token: "test_token".to_string(),
            cached_at: 1234567890,
            data: CacheData::default(),
        };
        
        let content = serde_json::to_string_pretty(&cache).unwrap();
        fs::write(&cache_path, &content).unwrap();
        
        let loaded: Cache = serde_json::from_str(&fs::read_to_string(&cache_path).unwrap()).unwrap();
        assert_eq!(loaded.sync_token, "test_token");
    }

    #[test]
    fn test_cache_expired() {
        let manager = CacheManager { cache_path: PathBuf::from("/nonexistent") };
        let old_cache = Cache {
            sync_token: "test".to_string(),
            cached_at: 1, // very old
            data: CacheData::default(),
        };
        assert!(manager.is_expired(&old_cache, 300));
    }
}
```

**Step 2: è¿è¡Œæµ‹è¯•**

Run: `cd .worktrees/local-cache && cargo test`
Expected: ALL PASS

**Step 3: æäº¤**

```bash
cd .worktrees/local-cache
git add tests/
git commit -m "test: add cache unit tests"
```

---

## Task 6: æœ€ç»ˆéªŒè¯

**Step 1: è¿è¡Œå®Œæ•´æµ‹è¯•**

Run: `cd .worktrees/local-cache && cargo test --all`
Expected: ALL PASS

**Step 2: æ„å»º release ç‰ˆæœ¬**

Run: `cd .worktrees/local-cache && cargo build --release`
Expected: SUCCESS

**Step 3: æäº¤**

```bash
cd .worktrees/local-cache
git add .
git commit -m "chore: ready for PR - local cache feature complete"
```

---

## æ‰§è¡Œé€‰æ‹©

**Plan complete and saved to `docs/plans/2026-02-16-local-cache-plan.md`. ä¸¤ä¸ªæ‰§è¡Œé€‰é¡¹:**

1. **Subagent-Driven (æœ¬ä¼šè¯)** - æ¯ä¸ªä»»åŠ¡ spawn ä¸€ä¸ªå­ä»£ç†ï¼Œä»»åŠ¡é—´ reviewï¼Œå¿«é€Ÿè¿­ä»£
2. **Parallel Session (æ–°ä¼šè¯)** - åœ¨ worktree ä¸­æ‰“å¼€æ–°ä¼šè¯ï¼Œç”¨ executing-plans æ‰¹é‡æ‰§è¡Œ

**é€‰å“ªä¸ªï¼Ÿ** ğŸ”®
